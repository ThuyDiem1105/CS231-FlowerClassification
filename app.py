import streamlit as st
import cv2
import numpy as np
import pickle
from PIL import Image
import io
import os
from sklearn.cluster import MiniBatchKMeans
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# --- C·∫§U H√åNH & H·∫∞NG S·ªê ---
# C√°c tham s·ªë tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng C·∫¶N PH·∫¢I GI·ªêNG H·ªÜT nh∆∞ trong notebook
K_VALUE = 700
HSV_BINS = (4, 4, 4) # 4*4*4 = 64 dimensions cho m·ªói histogram
IMG_SIZE = (256, 256)
sift = cv2.SIFT_create()

# --- 1. H√†m T·∫£i Model (ƒê√£ s·ª≠a) ---

@st.cache_resource
def load_all_components(path='bovw_sift_hsv_svm.pkl'):
    """T·∫£i t·∫•t c·∫£ c√°c th√†nh ph·∫ßn (kmeans, scaler, pca, model, names) t·ª´ file dictionary."""
    try:
        if not os.path.exists(path):
            st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y file model t·∫°i {path}. H√£y ch·∫Øc ch·∫Øn b·∫°n ƒë√£ ch·∫°y b∆∞·ªõc l∆∞u file trong notebook v√† ƒë·∫∑t file ƒë√∫ng ch·ªó.")
            return None, None, None, None, None
            
        with open(path, 'rb') as f:
            model_data = pickle.load(f)
            
            # Tr√≠ch xu·∫•t c√°c th√†nh ph·∫ßn t·ª´ dictionary
            kmeans = model_data.get('kmeans')
            scaler = model_data.get('scaler')
            pca = model_data.get('pca')
            svm_model = model_data.get('model')
            class_names = model_data.get('class_names')
            
            # Ki·ªÉm tra t√≠nh to√†n v·∫πn
            if None in [kmeans, scaler, pca, svm_model, class_names]:
                st.error("L·ªói: File model kh√¥ng ch·ª©a ƒë·ªß c√°c th√†nh ph·∫ßn (kmeans, scaler, pca, model, class_names).")
                return None, None, None, None, None

            st.success("‚úÖ Model (SVM), Visual Dictionary (KMeans), Scaler, v√† PCA ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
            return kmeans, scaler, pca, svm_model, class_names

    except Exception as e:
        st.error(f"L·ªói khi t·∫£i model: {e}")
        return None, None, None, None, None

# --- 2. H√†m Tr√≠ch xu·∫•t ƒê·∫∑c tr∆∞ng (RootSIFT, HSV) ---

def extract_rootsift_descriptors(img_gray, max_kp=500):
    """T√°i t·∫°o ch√≠nh x√°c h√†m RootSIFT t·ª´ notebook."""
    keypoints, desc = sift.detectAndCompute(img_gray, None)
    if desc is None:
        return None

    if desc.shape[0] > max_kp:
        desc = desc[:max_kp]
        
    # RootSIFT: L1 normalize + cƒÉn b·∫≠c hai
    desc = desc.astype("float32")
    desc /= (desc.sum(axis=1, keepdims=True) + 1e-7)
    desc = np.sqrt(desc)

    return desc

def extract_hsv_hist(img_bgr, bins=HSV_BINS):
    """Tr√≠ch xu·∫•t 3D HSV histogram (Hellinger) t·ª´ to√†n b·ªô ·∫£nh resize."""
    img_resized = cv2.resize(img_bgr, IMG_SIZE)
    hsv = cv2.cvtColor(img_resized, cv2.COLOR_BGR2HSV)

    hist = cv2.calcHist(
        [hsv], [0,1,2], None,
        bins,                       
        [0,180, 0,256, 0,256]
    )
    hist = hist.astype("float32").flatten()

    # Hellinger
    hist /= (hist.sum() + 1e-7)
    hist = np.sqrt(hist)
    return hist

def extract_center_hsv_hist(img_bgr, bins=HSV_BINS):
    """Tr√≠ch xu·∫•t 3D HSV histogram (Hellinger) t·ª´ √¥ gi·ªØa ·∫£nh."""
    h, w = img_bgr.shape[:2]
    # c·∫Øt √¥ gi·ªØa ·∫£nh (1/2 k√≠ch th∆∞·ªõc)
    x1, x2 = w//4, 3*w//4
    y1, y2 = h//4, 3*h//4
    center = img_bgr[y1:y2, x1:x2]

    hsv = cv2.cvtColor(center, cv2.COLOR_BGR2HSV)
    hist = cv2.calcHist([hsv],[0,1,2],None,bins,[0,180,0,256,0,256])
    hist = hist.astype("float32").flatten()
    
    # Hellinger
    hist /= (hist.sum() + 1e-7)
    hist = np.sqrt(hist)   
    return hist

def image_to_feature_vector(img_bgr, kmeans: MiniBatchKMeans, scaler: StandardScaler, pca: PCA):
    """
    T√°i t·∫°o to√†n b·ªô quy tr√¨nh tr√≠ch xu·∫•t v√† bi·∫øn ƒë·ªïi feature.
    Tr·∫£ v·ªÅ feature vector cu·ªëi c√πng (sau PCA).
    """
    img_resized = cv2.resize(img_bgr, IMG_SIZE)
    gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)

    # --- 1. BoVW t·ª´ RootSIFT ---
    desc = extract_rootsift_descriptors(gray)
    if desc is None:
        bovw_hist = np.zeros(K_VALUE, dtype=np.float32)
    else:
        words = kmeans.predict(desc)
        bovw_hist, _ = np.histogram(words, bins=np.arange(K_VALUE+1))
        bovw_hist = bovw_hist.astype("float32")
        # Hellinger
        bovw_hist /= (bovw_hist.sum() + 1e-7)
        bovw_hist = np.sqrt(bovw_hist)

    # --- 2. HSV color feature (Global & Center) ---
    global_hsv = extract_hsv_hist(img_resized, bins=HSV_BINS) 
    center_hsv = extract_center_hsv_hist(img_resized, bins=HSV_BINS)
    
    # --- 3. G·ªôp feature ---
    feat = np.hstack([bovw_hist, global_hsv, center_hsv]) # K + 64 + 64 = 828 dims
    feat = feat.reshape(1, -1) # ƒê·∫£m b·∫£o l√† m·∫£ng 2D

    # --- 4. Chu·∫©n h√≥a (StandardScaler) ---
    feats_scaled = scaler.transform(feat)

    # --- 5. Gi·∫£m chi·ªÅu (PCA) ---
    feats_pca = pca.transform(feats_scaled)
    
    return feats_pca


# --- 3. ·ª®ng d·ª•ng Streamlit ---

def main():
    st.set_page_config(page_title="üå∏ H·ªá th·ªëng Ph√¢n lo·∫°i Hoa Demo", layout="centered")
    
    st.title("üå∫ H·ªá th·ªëng Ph√¢n lo·∫°i Hoa D·ª±a tr√™n H√¨nh ·∫£nh")
    st.markdown("S·ª≠ d·ª•ng model **BoVW-RootSIFT + HSV + SVM** ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán.")
    
    # T·∫£i Model v√† c√°c th√†nh ph·∫ßn
    kmeans, scaler, pca, svm_model, class_names = load_all_components()
    
    if svm_model is None:
        st.stop() # D·ª´ng ·ª©ng d·ª•ng n·∫øu kh√¥ng t·∫£i ƒë∆∞·ª£c model ho·∫∑c thi·∫øu th√†nh ph·∫ßn

    uploaded_file = st.file_uploader(
        "T·∫£i l√™n h√¨nh ·∫£nh hoa (ƒê·ªãnh d·∫°ng: .jpg, .jpeg, .png)", 
        type=["jpg", "jpeg", "png"]
    )

    if uploaded_file is not None:
        try:
            # 1. Hi·ªÉn th·ªã h√¨nh ·∫£nh (D√πng PIL)
            image_pil = Image.open(uploaded_file)
            st.image(image_pil, caption='H√¨nh ·∫£nh ƒë∆∞·ª£c t·∫£i l√™n.', use_container_width=True) # ƒê√£ s·ª≠a c·∫£nh b√°o
            st.write("---")
            
            # Chuy·ªÉn ƒë·ªïi PIL Image sang m·∫£ng NumPy (OpenCV format - BGR)
            # D√πng PIL ƒë·ªÉ tr√°nh l·ªói cv2.imdecode nh∆∞ b·∫°n g·∫∑p tr∆∞·ªõc ƒë√≥
            img_np_rgb = np.array(image_pil)
            img_bgr = cv2.cvtColor(img_np_rgb, cv2.COLOR_RGB2BGR)
            
            if img_bgr is None or img_bgr.size == 0:
                st.error("Kh√¥ng th·ªÉ ƒë·ªçc file h√¨nh ·∫£nh. Vui l√≤ng th·ª≠ m·ªôt file kh√°c.")
                return

            # 2. Tr√≠ch xu·∫•t ƒê·∫∑c tr∆∞ng
            with st.spinner('ƒêang tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng (RootSIFT-BoVW, HSV, Scaling, PCA)...'):
                feature_vector = image_to_feature_vector(img_bgr, kmeans, scaler, pca)

            if feature_vector is not None:
                st.success(f"ƒê√£ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng th√†nh c√¥ng. K√≠ch th∆∞·ªõc vector cu·ªëi c√πng: {feature_vector.shape[1]}")
                
                # 3. D·ª± ƒëo√°n
                with st.spinner('ƒêang d·ª± ƒëo√°n lo·∫°i hoa...'):
                    # Model ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi probability=True
                    probabilities = svm_model.predict_proba(feature_vector)[0]
                    prediction = svm_model.predict(feature_vector)[0]
                    predicted_class_name = class_names[prediction]
                    
                    st.balloons()
                    st.header(f"‚ú® K·∫øt qu·∫£ Ph√¢n lo·∫°i: **{predicted_class_name.upper()}**")
                    
                    # Hi·ªÉn th·ªã ƒë·ªô tin c·∫≠y
                    confidence = probabilities[prediction] * 100
                    st.subheader(f"ƒê·ªô tin c·∫≠y: **{confidence:.2f}%**")
                    
                    # B·∫£ng x·∫øp h·∫°ng c√°c l·ªõp
                    st.write("### ƒê·ªô tin c·∫≠y chi ti·∫øt:")
                    
                    # S·∫Øp x·∫øp theo x√°c su·∫•t gi·∫£m d·∫ßn
                    sorted_indices = np.argsort(probabilities)[::-1]
                    
                    data = []
                    for i in sorted_indices:
                        data.append({
                            'Lo·∫°i Hoa': class_names[i].capitalize(),
                            'X√°c su·∫•t': f'{probabilities[i]*100:.2f}%'
                        })
                    
                    st.table(data)
                        
            else:
                st.error("Kh√¥ng th·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng.")

        except Exception as e:
            st.error(f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh x·ª≠ l√Ω: {e}")

if __name__ == '__main__':
    main()