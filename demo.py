import streamlit as st
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
from PIL import Image
import io
import pandas as pd
import os 
import warnings
import joblib 
import cv2  
from sklearn.base import BaseEstimator, ClassifierMixin 
from sklearn.svm import SVC 

warnings.filterwarnings('ignore') 

# =================================================================
# 1. C·∫§U H√åNH THAM S·ªê (PH·∫¢I KH·ªöP V·ªöI L√öC HU·∫§N LUY·ªÜN)
# =================================================================
# ƒê∆∞·ªùng d·∫´n cho c·∫£ hai m√¥ h√¨nh
MODEL_PATHS = {
    "ViT (Vision Transformer)": 'vit_flowers_model.weights.h5',
    "BoVW + SIFT + HSV (SVM)": 'bovw_sift_hsv_model.pkl' 
}

# Tham s·ªë K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o (Ph·∫£i kh·ªõp v·ªõi ViT v√† BoVW)
IMG_HEIGHT = 224
IMG_WIDTH = 224
IMAGE_SIZE = 224
INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)
NUM_CLASSES = 7
CLASS_NAMES = ['daisy', 'dandelion', 'lily', 'orchid', 'rose', 'sunflower', 'tulip']

# Tham s·ªë ViT
PATCH_SIZE = 16
NUM_PATCHES = 196 
PROJECTION_DIM = 128
NUM_HEADS = 4
TRANSFORMER_LAYERS = 6
MLP_UNITS = [256, 128]
MLP_HEAD_UNITS = [128]

# Tham s·ªë BoVW
K_CLUSTERS = 183 # <--- ƒê√É S·ª¨A: 192 (SVM features) - 9 (HSV features) = 183
# -----------------------------------------------------------------


# --- KI·ªÇM TRA ƒê∆Ø·ªúNG D·∫™N FILE M√î H√åNH ---
for name, path in MODEL_PATHS.items():
    if not os.path.exists(path):
        st.error(f"L·ªñI KH·ªûI T·∫†O: Kh√¥ng t√¨m th·∫•y file m√¥ h√¨nh `{name}` t·∫°i ƒë∆∞·ªùng d·∫´n: `{path}`")
        st.stop()


# =================================================================
# 2. H√ÄM TR√çCH XU·∫§T ƒê·∫∂C TR∆ØNG BOVW (Cho m√¥ h√¨nh SVM)
# =================================================================

def extract_bovw_features(image_cv, kmeans_model, k_clusters):
    """
    Th·ª±c hi·ªán tr√≠ch xu·∫•t SIFT v√† Color Histogram (HSV), sau ƒë√≥ t·∫°o vector BoVW.
    image_cv: ·∫¢nh ƒë√£ resize (d√πng cv2.resize) ·ªü ƒë·ªãnh d·∫°ng BGR.
    """
    
    # Chuy·ªÉn ƒë·ªïi ·∫£nh sang ·∫£nh x√°m cho SIFT
    gray_image = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)

    # 1. SIFT Extraction
    sift = cv2.SIFT_create()
    keypoints, descriptors = sift.detectAndCompute(gray_image, None)
    
    # 2. BoVW Histogram
    if descriptors is None or len(descriptors) == 0:
        # K√≠ch th∆∞·ªõc ph·∫£i l√† K_CLUSTERS + 9 (cho HSV)
        return np.zeros((1, k_clusters + 9), dtype=np.float32) 
    
    # Quantize SIFT descriptors
    try:
        # S·ª≠ d·ª•ng KMeans ƒë·ªÉ quantize (g√°n c·ª•m) descriptors
        clusters = kmeans_model.predict(descriptors)
    except AttributeError:
        # L·ªói n√†y ch·ªâ x·∫£y ra n·∫øu KMeans kh√¥ng ph·∫£i l√† m√¥ h√¨nh Scikit-learn h·ª£p l·ªá
        # N·∫øu g·∫∑p l·ªói n√†y, h√£y ki·ªÉm tra l·∫°i Kmeans Model ƒë∆∞·ª£c l∆∞u
        st.error("L·ªói: M√¥ h√¨nh KMeans kh√¥ng c√≥ ph∆∞∆°ng th·ª©c predict. Kh√¥ng th·ªÉ tr√≠ch xu·∫•t SIFT.")
        return np.zeros((1, k_clusters + 9), dtype=np.float32) 
        
    bovw_hist, _ = np.histogram(clusters, bins=range(k_clusters + 1), density=True)
    
    # 3. HSV Color Histogram (9 features: 3 bins per H, S, V)
    hsv_image = cv2.cvtColor(image_cv, cv2.COLOR_BGR2HSV)
    # L∆ØU √ù: N·∫øu m√¥ h√¨nh SVM c·ªßa b·∫°n ch·ªâ d√πng 3 bins cho H, S, V T·ªîNG C·ªòNG (t·ª©c 1 feature H, 1 feature S, 1 feature V)
    # th√¨ K_CLUSTERS = 189. Hi·ªán t·∫°i, ch√∫ng ta d√πng 9 features (3 bins cho m·ªói k√™nh)
    h_hist = cv2.calcHist([hsv_image], [0], None, [3], [0, 180]).flatten()
    s_hist = cv2.calcHist([hsv_image], [1], None, [3], [0, 256]).flatten()
    v_hist = cv2.calcHist([hsv_image], [2], None, [3], [0, 256]).flatten()
    
    color_hist = np.concatenate([h_hist, s_hist, v_hist])
    color_hist /= (color_hist.sum() + 1e-7) # Chu·∫©n h√≥a m√†u s·∫Øc
    
    # 4. Concatenate
    final_features = np.concatenate([bovw_hist, color_hist])
    return final_features.reshape(1, -1)


# =================================================================
# 3. KI·∫æN TR√öC VIT V√Ä H√ÄM T·∫¢I M√î H√åNH
# =================================================================

# --- Create Patches ---
class PatchLayer(layers.Layer):
    def call(self, images):
        patches = tf.image.extract_patches(
            images=images,
            sizes=[1, PATCH_SIZE, PATCH_SIZE, 1],
            strides=[1, PATCH_SIZE, PATCH_SIZE, 1],
            rates=[1, 1, 1, 1],
            padding="VALID"
        )
        patch_dim = PATCH_SIZE * PATCH_SIZE * 3
        return tf.reshape(patches, [-1, NUM_PATCHES, patch_dim])

# --- Patch Encoder (Linear Projection + Positional Encoding) ---
class PatchEncoder(layers.Layer):
    def __init__(self, num_patches=NUM_PATCHES, projection_dim=PROJECTION_DIM, **kwargs):
        super().__init__(**kwargs)
        self.num_patches = num_patches
        self.projection_dim = projection_dim
        self.projection = layers.Dense(projection_dim)
        self.position_embedding = layers.Embedding(
            input_dim=num_patches + 1, 
            output_dim=projection_dim
        )
        
    def call(self, patch_tokens):
        positions = tf.range(start=0, limit=self.num_patches)
        encoded = self.projection(patch_tokens) + self.position_embedding(positions)
        return encoded

    def get_config(self):
        config = super().get_config()
        config.update({
            "num_patches": self.num_patches,
            "projection_dim": self.projection_dim,
        })
        return config


# --- Transformer Encoder Block ---
def transformer_encoder(inputs):
    x = layers.LayerNormalization(epsilon=1e-6)(inputs)
    attn = layers.MultiHeadAttention(
        num_heads=NUM_HEADS, 
        key_dim=PROJECTION_DIM, 
        dropout=0.1
    )(x, x)
    attn = layers.Dropout(0.1)(attn)
    x = layers.Add()([attn, inputs])

    # FFN
    y = layers.LayerNormalization(epsilon=1e-6)(x)
    y = layers.Dense(MLP_UNITS[0], activation='gelu')(y)
    y = layers.Dropout(0.1)(y)
    y = layers.Dense(PROJECTION_DIM)(y)
    return layers.Add()([x, y])

# --- Build ViT model ---
def build_vit(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES):
    inputs = layers.Input(shape=input_shape)

    # 1) Make patches
    patches = PatchLayer()(inputs) 

    # 2) Patch encoding 
    patch_embeddings = PatchEncoder()(patches)

    # 3) class token variable (trainable)
    class_token = tf.Variable(
        tf.zeros((1, 1, PROJECTION_DIM)), 
        trainable=True, 
        name="class_token"
    )

    # 4) use a Lambda layer to repeat & concat class token
    def _prepend_token(patch_emb):
        batch = tf.shape(patch_emb)[0]
        tokens = tf.repeat(class_token, repeats=batch, axis=0)
        return tf.concat([tokens, patch_emb], axis=1)

    x = layers.Lambda(_prepend_token, name="prepend_class_token")(patch_embeddings)

    # 5) Transformer encoder stacks
    for i in range(TRANSFORMER_LAYERS):
        x = transformer_encoder(x)

    # 6) Take class token output (index 0)
    x = layers.LayerNormalization(epsilon=1e-6, name="pre_head_ln")(x[:, 0])

    # 7) MLP head
    for units in MLP_HEAD_UNITS:
        x = layers.Dense(units, activation="gelu")(x)
        x = layers.Dropout(0.2)(x)

    outputs = layers.Dense(num_classes, activation="softmax", name="predictions")(x)

    return tf.keras.Model(inputs=inputs, outputs=outputs, name="ViT_Flowers")

# --- T·∫¢I M√î H√åNH CHUNG ---
@st.cache_resource
def load_model(model_name):
    path = MODEL_PATHS[model_name]
    
    if model_name.startswith("ViT"):
        try:
            input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3) 
            num_classes = len(CLASS_NAMES)
            
            # X√¢y d·ª±ng l·∫°i ki·∫øn tr√∫c m√¥ h√¨nh ViT
            model = build_vit(input_shape, num_classes)
            model.load_weights(path)
            return model
        except Exception as e:
            st.error(f"L·ªói T·∫£i Tr·ªçng S·ªë ViT: {e}. Ki·∫øn tr√∫c kh√¥ng kh·ªõp.")
            print(f"[L·ªñI T·∫¢I VIT] Chi ti·∫øt: {e}")
            return None
            
    elif model_name.startswith("BoVW"):
        try:
            bovw_obj = joblib.load(path)
            
            # Kh·ªüi t·∫°o gi√° tr·ªã m·∫∑c ƒë·ªãnh
            kmeans_model = None
            svm_classifier = None
            
            # --- X·ª¨ L√ù L·ªñI BOVW (Ph√°t hi·ªán ƒë·ªëi t∆∞·ª£ng dict) ---
            if isinstance(bovw_obj, dict):
                st.info("Ph√°t hi·ªán: File PKL ch·ª©a ƒë·ªëi t∆∞·ª£ng `dict`. ƒêang t√¨m ki·∫øm KMeans v√† SVM theo kh√≥a...")
                
                # C∆° ch·∫ø t√¨m ki·∫øm linh ho·∫°t trong dict
                found_kmeans = False
                found_svm = False
                
                for key, obj in bovw_obj.items():
                    # T√¨m KMeans (c√≥ predict v√† t√™n ch·ª©a 'kmeans')
                    if hasattr(obj, 'predict') and obj.__class__.__name__.lower().find('kmeans') != -1:
                        kmeans_model = obj
                        found_kmeans = True
                    # T√¨m SVM/Pipeline (c√≥ predict v√† t√™n ch·ª©a 'svc' ho·∫∑c 'pipeline')
                    elif hasattr(obj, 'predict') and (obj.__class__.__name__.lower().find('svc') != -1 or obj.__class__.__name__.lower().find('pipeline') != -1):
                        svm_classifier = obj
                        found_svm = True

                if found_kmeans and found_svm:
                    return (kmeans_model, svm_classifier)
                elif found_kmeans and not found_svm:
                    st.warning("C·∫¢NH B√ÅO BOVW: Ph√°t hi·ªán KMeans, nh∆∞ng SVM Classifier b·ªã thi·∫øu trong dict.")
                    return (kmeans_model, None) # Tr·∫£ v·ªÅ tuple (KMeans, None)
                else:
                    st.error(f"L·ªói BoVW: Kh√¥ng t√¨m th·∫•y KMeans v√†/ho·∫∑c SVM Classifier trong dict. C√°c kh√≥a trong dict: {list(bovw_obj.keys())}")
                    return None
            
            # Tr∆∞·ªùng h·ª£p 2: Tuple (KMeans, SVM)
            elif isinstance(bovw_obj, tuple) and len(bovw_obj) == 2 and hasattr(bovw_obj[1], 'predict'):
                st.info("Ph√°t hi·ªán: Tuple (KMeans, SVM). S·ª≠ d·ª•ng c·∫£ hai.")
                return bovw_obj
            
            # Tr∆∞·ªùng h·ª£p 3: Ch·ªâ c√≥ KMeans (D·ª±a tr√™n l·ªói tr∆∞·ªõc)
            elif hasattr(bovw_obj, 'predict') and bovw_obj.__class__.__name__.lower().find('kmeans') != -1:
                st.warning("C·∫¢NH B√ÅO BOVW: Ph√°t hi·ªán ch·ªâ c√≥ M√¥ h√¨nh KMeans (T·ª´ v·ª±ng). Kh√¥ng c√≥ SVM Classifier.")
                return (bovw_obj, None)
            
            # C√°c tr∆∞·ªùng h·ª£p l·ªói kh√°c
            else:
                class_name_actual = bovw_obj.__class__.__name__
                st.error(f"C·∫•u tr√∫c file .pkl BoVW kh√¥ng x√°c ƒë·ªãnh. ƒê·ªëi t∆∞·ª£ng l√† lo·∫°i `{class_name_actual}`. Vui l√≤ng ki·ªÉm tra l·∫°i qu√° tr√¨nh l∆∞u m√¥ h√¨nh.")
                return None
                 
        except Exception as e:
            st.error(f"L·ªói T·∫£i M√¥ H√¨nh BoVW: {e}. Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c file .pkl.")
            print(f"[L·ªñI T·∫¢I BOVW] Chi ti·∫øt: {e}")
            return None
    return None

# --- H√ÄM D·ª∞ ƒêO√ÅN CHUNG ---
def predict_image(model_name, model_obj, image, size, class_names):
    
    # 1. Ti·ªÅn x·ª≠ l√Ω ·∫£nh PIL (Resize & RGB)
    img_resized = image.resize((size, size)).convert('RGB')
    
    if model_name.startswith("ViT"):
        # ********* LOGIC D·ª∞ ƒêO√ÅN VIT *********
        
        img_array = keras.preprocessing.image.img_to_array(img_resized) 
        img_array = np.expand_dims(img_array, axis=0) 
        img_array = img_array / 255.0 
        
        predictions = model_obj.predict(img_array)
        
        # L·∫•y x√°c su·∫•t
        results = [{'class': name, 'probability': prob} for name, prob in zip(class_names, predictions[0])]
        
    elif model_name.startswith("BoVW"):
        # ********* LOGIC D·ª∞ ƒêO√ÅN BOVW *********
        
        # model_obj c√≥ th·ªÉ l√† (KMeans, SVM) ho·∫∑c (KMeans, None)
        kmeans_model, svm_or_pipeline = model_obj
        
        # --- KI·ªÇM TRA M√î H√åNH THI·∫æU ---
        if svm_or_pipeline is None:
            # Th√¥ng b√°o l·ªói ƒë√£ ƒë∆∞·ª£c in ·ªü giao di·ªán b·ªüi load_model, ch·ªâ tr·∫£ v·ªÅ 0
            return [{'class': c, 'probability': 0.0} for c in class_names]
            
        # Chuy·ªÉn ƒë·ªïi PIL sang cv2 (numpy BGR)
        img_cv_rgb = np.array(img_resized)
        img_cv_bgr = cv2.cvtColor(img_cv_rgb, cv2.COLOR_RGB2BGR)
        
        # --- QUY TR√åNH TR√çCH XU·∫§T FEATURES (Ch·ªâ khi c√≥ KMeans) ---
        if kmeans_model is not None:
            # Tr√≠ch xu·∫•t SIFT + BoVW th·ªß c√¥ng
            features = extract_bovw_features(img_cv_bgr, kmeans_model, K_CLUSTERS)
        else:
            # Tr∆∞·ªùng h·ª£p l·ªói thi·∫øu KMeans (ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω trong load_model)
            st.error("L·ªñI BOVW: Kh√¥ng c√≥ KMeans/T·ª´ v·ª±ng ƒë·ªÉ tr√≠ch xu·∫•t SIFT/BoVW features.")
            return [{'class': c, 'probability': 0.0} for c in class_names]
            
        # --- TH·ª∞C HI·ªÜN D·ª∞ ƒêO√ÅN ---
        if features is not None and features.shape[1] == (K_CLUSTERS + 9):
            prediction_index = svm_or_pipeline.predict(features)[0]
            
            if hasattr(svm_or_pipeline, 'predict_proba'):
                probabilities = svm_or_pipeline.predict_proba(features)[0]
            else:
                probabilities = np.zeros(len(class_names))
                probabilities[prediction_index] = 1.0

            results = [{'class': name, 'probability': prob} for name, prob in zip(class_names, probabilities)]
        else:
             st.error(f"L·ªói D·ª± ƒëo√°n BoVW: K√≠ch th∆∞·ªõc vector features kh√¥ng kh·ªõp ({features.shape[1]} != {K_CLUSTERS + 9}).")
             return [{'class': c, 'probability': 0.0} for c in class_names]
        
    return results


# =================================================================
# 4. GIAO DI·ªÜN STREAMLIT
# =================================================================

st.title("üå∫ Demo Ph√¢n Lo·∫°i Hoa ƒêa M√¥ H√¨nh")
st.markdown("Ch·ªçn m·ªôt m√¥ h√¨nh (ViT ho·∫∑c BoVW) v√† t·∫£i l√™n ·∫£nh ƒë·ªÉ ki·ªÉm tra k·∫øt qu·∫£ ph√¢n lo·∫°i.")

# 4a. Thanh ch·ªçn m√¥ h√¨nh
selected_model_name = st.selectbox(
    "Ch·ªçn M√¥ H√¨nh Ph√¢n Lo·∫°i:",
    list(MODEL_PATHS.keys())
)

# T·∫£i m√¥ h√¨nh ƒë√£ ch·ªçn
model_obj = load_model(selected_model_name)

if model_obj is not None:
    st.success(f"‚úÖ M√¥ h√¨nh **{selected_model_name}** ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.")

    uploaded_file = st.file_uploader(
        "Ch·ªçn m·ªôt file ·∫£nh...", 
        type=["jpg", "jpeg", "png"]
    )

    if uploaded_file is not None:
        # ƒê·ªçc ·∫£nh t·ª´ file ƒë√£ upload
        image = Image.open(uploaded_file)
        
        # Hi·ªÉn th·ªã ·∫£nh
        st.image(image, caption='·∫¢nh ƒë√£ t·∫£i l√™n', use_container_width=True)
        st.write("")
        
        # N√∫t Ph√¢n lo·∫°i
        if st.button('Ph√¢n lo·∫°i ngay!'):
            with st.spinner(f'ƒêang ch·∫°y d·ª± ƒëo√°n b·∫±ng {selected_model_name}...'):
                
                # Th·ª±c hi·ªán d·ª± ƒëo√°n
                results = predict_image(selected_model_name, model_obj, image, IMAGE_SIZE, CLASS_NAMES)
                
                # S·∫Øp x·∫øp k·∫øt qu·∫£ theo x√°c su·∫•t gi·∫£m d·∫ßn
                results.sort(key=lambda x: x['probability'], reverse=True)
                
                best_pred = results[0]

                # Hi·ªÉn th·ªã k·∫øt qu·∫£ ch√≠nh
                st.success(f"‚úÖ D·ª∞ ƒêO√ÅN HO√ÄN T·∫§T!")
                st.markdown(f"**Lo·∫°i Hoa D·ª± ƒêo√°n l√†:** <span style='font-size: 24px; color: #ff4b4b;'>{best_pred['class'].capitalize()}</span>", unsafe_allow_html=True)
                st.markdown(f"**ƒê·ªô t·ª± tin:** `{best_pred['probability']:.2%}`")
                
                st.write("---")

                # Hi·ªÉn th·ªã b·∫£ng x√°c su·∫•t chi ti·∫øt
                st.subheader("B·∫£ng X√°c Su·∫•t Chi Ti·∫øt")
                
                # ƒê·ªãnh d·∫°ng d·ªØ li·ªáu cho DataFrame
                df_results = pd.DataFrame([
                    {'Lo·∫°i Hoa': r['class'].capitalize(), 'X√°c Su·∫•t': f"{r['probability']:.2%}"} 
                    for r in results
                ])
                st.dataframe(df_results, use_container_width=True, hide_index=True)

else:
    # N·∫øu t·∫£i m√¥ h√¨nh l·ªói, th√¥ng b√°o l·ªói c·ª• th·ªÉ ƒë√£ ƒë∆∞·ª£c hi·ªÉn th·ªã b√™n trong load_model
    st.error("‚ö†Ô∏è ·ª®ng d·ª•ng kh√¥ng th·ªÉ kh·ªüi ƒë·ªông do l·ªói t·∫£i m√¥ h√¨nh. Vui l√≤ng ki·ªÉm tra c√°c th√¥ng b√°o l·ªói c·ª• th·ªÉ.")