import streamlit as st
import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
import pickle
from PIL import Image
import os
# Import ViTConfig v√† TFViTModel ƒë·ªÉ t√°i t·∫°o ki·∫øn tr√∫c
from transformers import ViTConfig, TFViTModel 
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler

# =================================================================
# 1. C·∫§U H√åNH THAM S·ªê V√Ä KHAI B√ÅO
# =================================================================
IMG_HEIGHT = 224
IMG_WIDTH = 224
INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, 3)
PRETRAINED_MODEL = "google/vit-base-patch16-224"

# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c file ƒë√£ l∆∞u (Ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n n√†y!)
FEATURE_EXTRACTOR_WEIGHTS_PATH = 'feature_extractor.weights.h5'
SVM_MODEL_PATH = 'svm_classifier.pkl'
SCALER_PATH = 'feature_scaler.pkl'
# C·∫¨P NH·∫¨T CLASS NAMES C·ª¶A B·∫†N (7 L·ªöP)
CLASS_NAMES = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip', 'class_5', 'class_6'] 

# =================================================================
# 2. ƒê·ªäNH NGHƒ®A L·ªöP B·ªåC (T√°i t·∫°o ki·∫øn tr√∫c ViT)
# =================================================================
class ViTFeatureExtractorLayer(tf.keras.layers.Layer):
    """G√≥i TFViTModel. Kh·ªüi t·∫°o model t·ª´ Config ƒë·ªÉ tr√°nh l·ªói loading PyTorch weights."""
    def __init__(self, model_name=PRETRAINED_MODEL, **kwargs):
        super().__init__(**kwargs)
        self.model_name = model_name
        self.vit_model = None 

    def build(self, input_shape):
        if self.vit_model is None:
            # 1. T·∫£i c·∫•u h√¨nh ViT
            config = ViTConfig.from_pretrained(self.model_name)
            
            # 2. Kh·ªüi t·∫°o TFViTModel t·ª´ Config (t·∫°o model t·ª´ scratch)
            self.vit_model = TFViTModel(config, name='vit_transfer')
            self.vit_model.config.output_hidden_states = True
            self.vit_model.config.output_attentions = False
            
        super().build(input_shape)

    def call(self, inputs):
        # inputs ph·∫£i l√† (N, C, H, W)
        outputs = self.vit_model(pixel_values=inputs, training=False)
        return outputs.pooler_output

# =================================================================
# 3. H√ÄM X√ÇY D·ª∞NG KI·∫æN TR√öC FEATURE EXTRACTOR
# =================================================================
def build_feature_extractor_architecture():
    """X√¢y d·ª±ng ki·∫øn tr√∫c Feature Extractor ƒë√∫ng nh∆∞ trong code training."""
    
    inputs = layers.Input(shape=INPUT_SHAPE, name='pixel_values')
    
    x = layers.Normalization(
        mean=[0.5, 0.5, 0.5],
        variance=[0.25, 0.25, 0.25]
    )(inputs)

    x = layers.Permute((3, 1, 2))(x)
    
    vit_feature_layer = ViTFeatureExtractorLayer(model_name=PRETRAINED_MODEL)
    features_vit = vit_feature_layer(x) 
    
    # C√°c l·ªõp Dense d√πng ƒë·ªÉ tr√≠ch xu·∫•t features cu·ªëi c√πng
    features = layers.Dense(256, activation="gelu", name="feature_dense_1")(features_vit)
    features = layers.Dropout(0.5, name="feature_dropout_1")(features)
    features = layers.Dense(128, activation="gelu", name="feature_dense_2")(features)
    
    feature_extractor = tf.keras.Model(
        inputs=inputs,
        outputs=features,
        name="ViT_Transfer_FeatureExtractor"
    )
    return feature_extractor

# =================================================================
# 4. H√ÄM T·∫¢I M√î H√åNH V√Ä SCALER (S·ª¨ D·ª§NG CACHING)
# =================================================================
@st.cache_resource
def load_feature_extractor():
    """T·∫£i v√† cache Feature Extractor Model (TF Model l·ªõn)."""
    st.write("ƒêang x√¢y d·ª±ng ki·∫øn tr√∫c ViT Feature Extractor...")
    feature_extractor = build_feature_extractor_architecture()
    
    st.write("ƒêang t·∫£i ViT Feature Extractor weights ƒë√£ l∆∞u...")
    try:
        if not os.path.exists(FEATURE_EXTRACTOR_WEIGHTS_PATH):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file weights: {FEATURE_EXTRACTOR_WEIGHTS_PATH}")
        feature_extractor.load_weights(FEATURE_EXTRACTOR_WEIGHTS_PATH)
        st.success("T·∫£i ViT Feature Extractor weights th√†nh c√¥ng!")
        return feature_extractor
    except Exception as e:
        st.error(f"‚ùå L·ªói t·∫£i ViT weights: {e}")
        return None

@st.cache_data
def load_svm_and_scaler():
    """T·∫£i v√† cache SVM v√† Scaler (c√°c ƒë·ªëi t∆∞·ª£ng pickle)."""
    
    # T·∫£i SVM Classifier
    st.write("ƒêang t·∫£i SVM Classifier...")
    try:
        if not os.path.exists(SVM_MODEL_PATH):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file SVM: {SVM_MODEL_PATH}")
        with open(SVM_MODEL_PATH, 'rb') as f:
            svm_model = pickle.load(f)
        st.success("T·∫£i SVM model th√†nh c√¥ng!")
    except Exception as e:
        st.error(f"‚ùå L·ªói t·∫£i SVM model: {e}")
        return None, None

    # T·∫£i StandardScaler
    st.write("ƒêang t·∫£i StandardScaler...")
    try:
        if not os.path.exists(SCALER_PATH):
            raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y file Scaler: {SCALER_PATH}")
        with open(SCALER_PATH, 'rb') as f:
            scaler = pickle.load(f)
        st.success("T·∫£i StandardScaler th√†nh c√¥ng!")
    except Exception as e:
        st.error(f"‚ùå L·ªói t·∫£i StandardScaler: {e}")
        return None, None
        
    return svm_model, scaler

# =================================================================
# 5. H√ÄM TI·ªÄN X·ª¨ L√ù V√Ä D·ª∞ ƒêO√ÅN
# =================================================================
def preprocess_image(image):
    """Ti·ªÅn x·ª≠ l√Ω ·∫£nh cho ViT."""
    img = image.resize((IMG_WIDTH, IMG_HEIGHT))
    img_array = np.array(img, dtype=np.float32) / 255.0
    img_tensor = tf.expand_dims(img_array, 0)
    return img_tensor

def predict_class(image_tensor, feature_extractor, scaler, svm_model, class_names):
    """Tr√≠ch xu·∫•t features, chu·∫©n h√≥a v√† d·ª± ƒëo√°n b·∫±ng SVM."""
    # Tr√≠ch xu·∫•t Features (ch·ªâ ch·∫°y inference)
    features = feature_extractor.predict(image_tensor, verbose=0)
    
    # Chu·∫©n h√≥a Features
    features_scaled = scaler.transform(features)
    
    # D·ª± ƒëo√°n b·∫±ng SVM
    pred_class_index = svm_model.predict(features_scaled)[0]
    
    return class_names[pred_class_index], pred_class_index

# =================================================================
# 6. GIAO DI·ªÜN STREAMLIT
# =================================================================
st.set_page_config(
    page_title="Demo: ViT + SVM Ph√¢n Lo·∫°i Hoa",
    layout="centered",
    initial_sidebar_state="expanded",
)

st.title("üå∫ Demo Ph√¢n Lo·∫°i Hoa: ViT Transfer Learning + SVM")
st.subheader("M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán: ViT Feature Extractor + SVM (Kernel RBF)")
st.markdown("---")

# T·∫£i m√¥ h√¨nh b·∫±ng c√°c h√†m cache ƒë√£ t√°ch bi·ªát
feature_extractor = load_feature_extractor()
svm_model, scaler = load_svm_and_scaler()

if feature_extractor is None or svm_model is None or scaler is None:
    st.error("‚ùå Kh√¥ng th·ªÉ t·∫£i ƒë·ªß c√°c th√†nh ph·∫ßn m√¥ h√¨nh. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n file v√† c√°c th√¥ng b√°o l·ªói t·∫£i ·ªü tr√™n.")
else:
    st.success("‚úÖ T·∫£i m√¥ h√¨nh th√†nh c√¥ng. B·∫Øt ƒë·∫ßu Demo!")
    
    # Upload ·∫£nh
    uploaded_file = st.file_uploader(
        "T·∫£i l√™n m·ªôt h√¨nh ·∫£nh hoa:", 
        type=["png", "jpg", "jpeg"]
    )

    if uploaded_file is not None:
        # ƒê·ªçc ·∫£nh
        image = Image.open(uploaded_file).convert("RGB")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.image(image, caption='·∫¢nh t·∫£i l√™n', use_column_width=True)

        with col2:
            st.markdown("### üîç K·∫øt qu·∫£ D·ª± ƒëo√°n")
            
            # Ti·ªÅn x·ª≠ l√Ω
            with st.spinner('ƒêang ti·ªÅn x·ª≠ l√Ω v√† tr√≠ch xu·∫•t features...'):
                image_tensor = preprocess_image(image)
            
            # D·ª± ƒëo√°n
            with st.spinner('ƒêang d·ª± ƒëo√°n b·∫±ng SVM...'):
                pred_class, pred_index = predict_class(
                    image_tensor, 
                    feature_extractor, 
                    scaler, 
                    svm_model, 
                    CLASS_NAMES
                )
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            st.metric(
                label="L·ªõp Hoa D·ª± ƒêo√°n:", 
                value=f"**{pred_class.upper()}**", 
                delta=None
            )
            st.success("üéâ D·ª± ƒëo√°n ho√†n t·∫•t!")
            
            st.markdown("---")
            st.markdown(f"**Th√¥ng tin chi ti·∫øt:**")
            st.markdown(f"* **M√¥ h√¨nh Tr√≠ch xu·∫•t:** ViT-base-patch16-224 (T√°i t·∫°o ki·∫øn tr√∫c)")
            st.markdown(f"* **B·ªô ph√¢n lo·∫°i:** Support Vector Machine (Kernel: RBF)")

st.markdown("---")
st.caption("·ª®ng d·ª•ng demo b·ªüi Gemini. Vui l√≤ng ƒë·∫£m b·∫£o `tensorflow`, `transformers`, `scikit-learn` ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t.")